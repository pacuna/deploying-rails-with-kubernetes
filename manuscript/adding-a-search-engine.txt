### Adding a Search Engine

In order to make things more interesting and to put ourselves in a more
realistic scenario, let's add a search engine to our application.

Elasticsearch has a really nice integration with Rails via
the [elasticsearch-rails gem](https://github.com/elastic/elasticsearch-rails).

The steps we need to follow in order to add this gem to our project are:

1. Add the necessary gems
2. Add the new service to our docker-compose.yml file
3. Add the initializer for connecting with elasticsearch
4. Add the Elasticsearch modules to our Article model
5. Run `docker-compose` build and `docker-compose up`

Open the Gemfile an add the following:


    gem 'elasticsearch-model', git: 'git://github.com/elasticsearch/elasticsearch-rails.git'
    gem 'elasticsearch-rails', git: 'git://github.com/elasticsearch/elasticsearch-rails.git'

And then run `bundle install` inside of the container:

    docker exec -it myapp bash
    # bundle install

We are going to use the [official DockerHub image for elasticsearch](https://hub.docker.com/_/elasticsearch/)
in our docker-compose.yml file. Add the following service:


Now open the docker-compose.yml file and add the following services:

    elasticsearch:
      image: elasticsearch:2.3
      container_name: myapp-es
      volumes_from:
        - elasticsearch-data
      networks:
        - back-end
    elasticsearch-data:
      image: elasticsearch:2.3
      container_name: myapp-es-data
      volumes:
        - /var/lib/elasticsearch
      command: /bin/true

As you can see, we're also adding a data only container for persisting
the Elasticsearch data locally in case we need to recreate our container.

In order to use the gem in our Rails application, we must add an initializer
with the configuration. Create a new file under config/initializers/elasticsearch.rb
with the following code:


    host = 'elasticsearch'

    Elasticsearch::Model.client = Elasticsearch::Client.new host: "http://#{host}:9200"

    # Print Curl-formatted traces in development into a file
    #
    if Rails.env.development?
      tracer = ActiveSupport::Logger.new('log/elasticsearch.log')
      tracer.level =  Logger::DEBUG
    end

    Elasticsearch::Model.client.transport.tracer = tracer

We can use the host `elasticsearch` for this service since we declared it
with that name in our network in the docker-compose.yml.
Let's also create a task under lib/tasks/elasticsearch.rake with the following:


    require 'elasticsearch/rails/tasks/import'

This will gives us a handy command for indexing all records for the models
associated to the elasticsearch documents.

Right now we only have the Article model so open app/models/article.rb and
add the following:

    class Article < ApplicationRecord
      include Elasticsearch::Model
      include Elasticsearch::Model::Callbacks
    end

Those modules will include the necessary hooks for indexing the records.

Now we can run docker-compose:

    docker-compose build
    docker-compose up

Now, let's add a couple of records to our database:

    docker exec -it myapp bash
    # rails c
    > Article.create(title: 'article 1', body: 'body for article 1')
    > Article.create(title: 'article 2', body: 'body for article 2')
    > Article.create(title: 'article 3', body: 'body for article 3')

This article should be indexed immediately thanks to the callbacks
added by the Elasticsearch modules in the model. Let's perform a search
just to be sure:

    > Article.search("3").results.first
    => #<Elasticsearch::Model::Response::Result:0x0000000467f508 @result=#<Hashie::Mash _id="4" _index="articles" _score=0.30935922 _source=#<Hashie::Mash body="body for article 3" created_at="2016-05-08T00:49:37.329Z" id=4 title="article 3" updated_at="2016-05-08T00:49:37.329Z"> _type="article">>

If you have previous records you want to index, you can run the task
provided by the gem:

    # bundle exec rake environment elasticsearch:import:model CLASS='Article'
    [IMPORT] Done

And that's it! We have a production-ready search engine for our application.
